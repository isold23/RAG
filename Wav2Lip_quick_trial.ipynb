{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isold23/RAG/blob/main/Wav2Lip_quick_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSQFs_G8caeE"
      },
      "source": [
        "# Collab preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVB0Xn1g6ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36741d05-e838-453d-a3da-0c700fdc45f8"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d3a518-e4b0-4c0c-df27-2311b35009fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5taGmPcWV-"
      },
      "source": [
        "# Get the code and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501b90b0-f788-48eb-c6a6-e2444a13a2ab"
      },
      "source": [
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 369, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 369 (delta 4), reused 2 (delta 1), pack-reused 360\u001b[K\n",
            "Receiving objects: 100% (369/369), 528.94 KiB | 941.00 KiB/s, done.\n",
            "Resolving deltas: 100% (202/202), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-19nzx8SamJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e54e0bd-5855-4454-d1a8-fa6cb98a2a76"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/Wav2Lip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.wav  wav2lip_gan.pth  wav2lip.gif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzMPy_Sb0AI",
        "outputId": "e101aea3-26a8-43d1-dff6-f793359b9f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cp -ri \"/content/gdrive/MyDrive/Wav2Lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: overwrite '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'? y\n",
            "y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWTaOS3ncFt6"
      },
      "source": [
        "# Get the pre-requisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c87acda-ef04-433a-821a-e79b338fb04b"
      },
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dCYlLdcK2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6276aad1-9d2b-4ca8-db1a-1c8d3051b834"
      },
      "source": [
        "!cd Wav2Lip && pip install -r requirements.txt"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting librosa==0.7.0 (from -r requirements.txt (line 1))\n",
            "  Using cached librosa-0.7.0.tar.gz (1.6 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.17.1 (from -r requirements.txt (line 2))\n",
            "  Using cached numpy-1.17.1.zip (6.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-contrib-python>=4.2.0.34 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.8.0.76)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.1.0.25\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_bN4M6X_95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb63e6ac-d7f5-4cd9-85e4-cc425b1af4dd"
      },
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-01 08:48:43--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "Wav2Lip/face_detect 100%[===================>]  85.68M  21.3MB/s    in 4.0s    \n",
            "\n",
            "2023-11-01 08:48:47 (21.3 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdIQfY2Kswcb"
      },
      "source": [
        "# Now lets try!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoVGMtjRZfeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e1971c-ff75-4334-fc4a-3d9fd06ecb68"
      },
      "source": [
        "!cp \"/content/gdrive/My Drive/Wav2Lip/test.mp4\" \"/content/gdrive/My Drive/Wav2Lip/test.wav\" sample_data/\n",
        "!ls sample_data/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/gdrive/My Drive/Wav2Lip/test.mp4': No such file or directory\n",
            "anscombe.json\t\t     california_housing_train.csv  mnist_train_small.csv  test.wav\n",
            "california_housing_test.csv  mnist_test.csv\t\t   README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5utmDMcSZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d799af26-ecec-4aeb-87b7-cc89afb27107"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/test.mp4\" --audio \"../sample_data/test.wav\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 84\n",
            "(80, 98)\n",
            "Length of mel chunks: 27\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[ATHCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=383 error=11 : invalid argument\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "Recovering from OOM error; New batch size: 8\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 1/4 [00:00<00:02,  1.39it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  1.89it/s]\u001b[A\n",
            "100% 4/4 [00:01<00:00,  2.73it/s]\n",
            "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "100% 1/1 [00:05<00:00,  5.85s/it]\n",
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from '../sample_data/test.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:01.22, bitrate: 256 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.26.101\n",
            "  Duration: 00:00:01.08, start: 0.000000, bitrate: 427 kb/s\n",
            "    Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 160x160 [SAR 1:1 DAR 1:1], 394 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mprofile High, level 1.1\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/result_voice.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 160x160 [SAR 1:1 DAR 1:1], q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 16000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 aac\n",
            "frame=   27 fps=0.0 q=-1.0 Lsize=      30kB time=00:00:01.21 bitrate= 202.0kbits/s speed=17.5x    \n",
            "video:18kB audio:10kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 7.071869%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mframe I:1     Avg QP:24.19  size:  3270\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mframe P:16    Avg QP:25.33  size:   757\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mframe B:10    Avg QP:28.21  size:   189\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mconsecutive B-frames: 44.4% 14.8% 11.1% 29.6%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mmb I  I16..4:  4.0% 69.0% 27.0%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mmb P  I16..4:  1.0%  1.6%  0.2%  P16..4: 43.7% 22.6% 15.6%  0.0%  0.0%    skip:15.3%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mmb B  I16..4:  0.3%  1.0%  0.0%  B16..8: 48.3%  8.8%  1.4%  direct: 1.9%  skip:38.3%  L0:38.7% L1:44.5% BI:16.8%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0m8x8 transform intra:66.2% inter:64.6%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mcoded y,uvDC,uvAC intra: 71.7% 72.6% 29.9% inter: 23.7% 14.3% 0.5%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mi16 v,h,dc,p: 43% 17% 35%  4%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 13% 35%  4%  4%  8%  5%  4%  3%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 10% 10%  4%  8% 11%  5%  7%  2%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mi8c dc,h,v,p: 59% 15% 20%  6%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mWeighted P-Frames: Y:6.2% UV:6.2%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mref P L0: 65.4% 24.3%  8.3%  1.9%  0.1%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mref B L0: 90.8%  7.7%  1.5%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mref B L1: 98.6%  1.4%\n",
            "\u001b[1;36m[libx264 @ 0x55f3bd122d00] \u001b[0mkb/s:127.97\n",
            "\u001b[1;36m[aac @ 0x55f3bd170000] \u001b[0mQavg: 4839.380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOAZvkszEOw"
      },
      "source": [
        "# use the \"files\" button on the left to download the result in the Wav2Lip/results/ folder."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7zgfrQqbKom"
      },
      "source": [
        "## **Variations to try**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9A9VDVbZAG"
      },
      "source": [
        "1.   Use more padding to include the chin region"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45XW4SZAzIz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48902795-c336-4f15-c943-3f932f5e83e1"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/test.mp4\" --audio \"../sample_data/sdfnsdkgnjksdgv.wav\" --pads 0 20 0 0"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Wav2Lip/inference.py\", line 280, in <module>\n",
            "    main()\n",
            "  File \"/content/Wav2Lip/inference.py\", line 183, in main\n",
            "    raise ValueError('--face argument must be a valid path to video/image file')\n",
            "ValueError: --face argument must be a valid path to video/image file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-WnsxfbwTG"
      },
      "source": [
        "2.   Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0xFtZ2bsx8"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\" --resize_factor 2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}